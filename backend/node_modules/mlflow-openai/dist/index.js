"use strict";
/**
 * Main tracedOpenAI wrapper function for MLflow tracing integration
 */
Object.defineProperty(exports, "__esModule", { value: true });
exports.tracedOpenAI = tracedOpenAI;
const mlflow_tracing_1 = require("mlflow-tracing");
// NB: 'Completions' represents chat.completions
const SUPPORTED_MODULES = ['Completions', 'Responses', 'Embeddings'];
const SUPPORTED_METHODS = ['create']; // chat.completions.create, embeddings.create, responses.create
/**
 * Create a traced version of OpenAI client with MLflow tracing
 * @param openaiClient - The OpenAI client instance to trace
 * @param config - Optional configuration for tracing
 * @returns Traced OpenAI client with tracing capabilities
 *
 * @example
 * const openai = new OpenAI({ apiKey: 'test-key' });
 * const wrappedOpenAI = tracedOpenAI(openai);
 *
 * const response = await wrappedOpenAI.chat.completions.create({
 *   messages: [{ role: 'user', content: 'Hello!' }],
 *   model: 'gpt-4o-mini',
 *   temperature: 0.5
 * });
 *
 * // The trace for the LLM call will be logged to MLflow
 *
 */
function tracedOpenAI(openaiClient) {
    /**
     * Create a proxy to intercept method calls
     */
    const tracedClient = new Proxy(openaiClient, {
        get(target, prop, receiver) {
            const original = Reflect.get(target, prop, receiver);
            const moduleName = target.constructor.name;
            if (typeof original === 'function') {
                // If reach to the end function to be traced, wrap it with tracing
                if (shouldTraceMethod(moduleName, String(prop))) {
                    // eslint-disable-next-line @typescript-eslint/ban-types
                    return wrapWithTracing(original, moduleName);
                }
                // eslint-disable-next-line @typescript-eslint/ban-types
                return original.bind(target);
            }
            // For nested objects (like chat.completions), recursively apply tracking
            if (original &&
                !Array.isArray(original) &&
                !(original instanceof Date) &&
                typeof original === 'object') {
                return tracedOpenAI(original);
            }
            return original;
        }
    });
    return tracedClient;
}
/**
 * Determine if a method should be traced based on the target object and property
 */
function shouldTraceMethod(module, methodName) {
    return SUPPORTED_MODULES.includes(module) && SUPPORTED_METHODS.includes(methodName);
}
/**
 * Wrap a function with tracing using the full method path
 *
 * @param fn - The function to wrap
 * @param target - The target module that contains the function to wrap
 * @returns The wrapped function
 */
// eslint-disable-next-line @typescript-eslint/ban-types
function wrapWithTracing(fn, moduleName) {
    // Use the full method path for span type determination
    const spanType = getSpanType(moduleName);
    const name = moduleName;
    return function (...args) {
        // If the method is not supported, return the original function
        if (!spanType) {
            // eslint-disable-next-line @typescript-eslint/no-unsafe-return
            return fn.apply(this, args);
        }
        // eslint-disable-next-line @typescript-eslint/no-unsafe-return
        return (0, mlflow_tracing_1.withSpan)(async (span) => {
            span.setInputs(args[0]);
            const result = await fn.apply(this, args);
            // TODO: Handle streaming responses
            span.setOutputs(result);
            // Add token usage
            try {
                const usage = extractTokenUsage(result);
                if (usage) {
                    span.setAttribute(mlflow_tracing_1.SpanAttributeKey.TOKEN_USAGE, usage);
                }
            }
            catch (error) {
                console.debug('Error extracting token usage', error);
            }
            // eslint-disable-next-line @typescript-eslint/no-unsafe-return
            return result;
        }, { name, spanType });
    };
}
/**
 * Determine span type based on the full method path
 */
function getSpanType(moduleName) {
    switch (moduleName) {
        case 'Completions':
            return mlflow_tracing_1.SpanType.LLM;
        case 'Responses':
            return mlflow_tracing_1.SpanType.LLM;
        case 'Embeddings':
            return mlflow_tracing_1.SpanType.EMBEDDING;
        // TODO: Support other methods in the future.
        default:
            return undefined;
    }
}
/**
 * Extract token usage information from OpenAI response
 * Supports both ChatCompletion API format and Responses API format
 */
function extractTokenUsage(response) {
    // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access
    const usage = response?.usage;
    if (!usage) {
        return undefined;
    }
    // Try Responses API format first (input_tokens, output_tokens)
    if ('input_tokens' in usage) {
        return {
            input_tokens: usage.input_tokens,
            output_tokens: usage.output_tokens,
            total_tokens: usage.total_tokens || usage.input_tokens + usage.output_tokens
        };
    }
    // Fall back to ChatCompletion API format (prompt_tokens, completion_tokens)
    if ('prompt_tokens' in usage) {
        return {
            input_tokens: usage.prompt_tokens,
            output_tokens: usage.completion_tokens,
            total_tokens: usage.total_tokens || usage.prompt_tokens + usage.completion_tokens
        };
    }
    return undefined;
}
